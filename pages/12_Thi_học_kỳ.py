import streamlit as st
import cv2
import numpy as np
import joblib
from PIL import Image
import os
import matplotlib.pyplot as plt

st.set_page_config(
    page_title="Nh·∫≠n Di·ªán C·∫£m X√∫c T·ª´ Khu√¥n M·∫∑t",
    layout="wide",
    initial_sidebar_state="expanded",
)

Model_DIR = "./models/Thi_hoc_ky"
Data_DIR ="./data/Thi_hoc_ky"
# T·∫£i m√¥ h√¨nh v√† Haar Cascade
model = joblib.load("./models/thi_hoc_ky/emotion_recognition_model.pkl")
cascade = os.path.join(Model_DIR, "haarcascade_frontalface_default.xml")
emotions = ["happy", "sadness", "neutral"]  # Danh s√°ch c·∫£m x√∫c

# Ph·∫ßn 1: M√¥ t·∫£ D·ªØ Li·ªáu
st.title("M√¥ T·∫£ D·ªØ Li·ªáu C·∫£m X√∫c T·ª´ Khu√¥n M·∫∑t")
st.markdown("""
### D·ªØ li·ªáu bao g·ªìm c√°c b·ª©c ·∫£nh v·ªõi c√°c c·∫£m x√∫c kh√°c nhau: happy, sad, v√† neutral.
D∆∞·ªõi ƒë√¢y l√† 3 v√≠ d·ª• khu√¥n m·∫∑t t·ª´ dataset cho m·ªói lo·∫°i c·∫£m x√∫c.
""")

# Hi·ªÉn th·ªã ·∫£nh t·ª´ dataset trong 3 c·ªôt song song
col1, col2, col3 = st.columns(3)

# L·∫•y ƒë∆∞·ªùng d·∫´n t·ªõi ·∫£nh cho m·ªói lo·∫°i c·∫£m x√∫c
data_examples = {emotion: os.listdir(os.path.join(Data_DIR, emotion))[:3] for emotion in emotions}

# Hi·ªÉn th·ªã ·∫£nh
with col1:
    st.subheader("Happy")
    for img_name in data_examples["happy"]:
        img_path = os.path.join(Data_DIR, "happy", img_name)
        img_data = Image.open(img_path)
        st.image(img_data, caption="Happy", use_column_width=True)

with col2:
    st.subheader("sadness")
    for img_name in data_examples["sadness"]:
        img_path = os.path.join(Data_DIR, "sadness", img_name)
        img_data = Image.open(img_path)
        st.image(img_data, caption="sadness", use_column_width=True)

with col3:
    st.subheader("Neutral")
    for img_name in data_examples["neutral"]:
        img_path = os.path.join(Data_DIR, "neutral", img_name)
        img_data = Image.open(img_path)
        st.image(img_data, caption="Neutral", use_column_width=True)



#  Bi·ªÉu Di·ªÖn S∆° ƒê·ªì Minh H·ªça Lu·ªìng X·ª≠ L√Ω
# Ti√™u ƒë·ªÅ trang
st.title("Minh H·ªça Lu·ªìng X·ª≠ L√Ω Nh·∫≠n Di·ªán C·∫£m X√∫c üéØ")

# M√¥ t·∫£ lu·ªìng x·ª≠ l√Ω
st.markdown("""
### **Lu·ªìng X·ª≠ L√Ω**
·ª®ng d·ª•ng nh·∫≠n di·ªán c·∫£m x√∫c t·ª´ khu√¥n m·∫∑t bao g·ªìm c√°c b∆∞·ªõc ch√≠nh nh∆∞ sau:

1. **Nh·∫≠p D·ªØ Li·ªáu**
   - Ng∆∞·ªùi d√πng t·∫£i ·∫£nh l√™n ho·∫∑c s·ª≠ d·ª•ng webcam.
2. **Ti·ªÅn X·ª≠ L√Ω ·∫¢nh**
   - ·∫¢nh ƒë·∫ßu v√†o ƒë∆∞·ª£c chuy·ªÉn sang d·∫°ng grayscale v√† ph√°t hi·ªán khu√¥n m·∫∑t.
3. **Nh·∫≠n di·ªán khu√¥n m·∫∑t v√† Tr√≠ch Xu·∫•t ƒê·∫∑c Tr∆∞ng**
   - C·∫Øt khu√¥n m·∫∑t, resize ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n (48x48), chuy·ªÉn ƒë·ªïi th√†nh vector.
4. **D·ª± ƒêo√°n C·∫£m X√∫c**
   - S·ª≠ d·ª•ng m√¥ h√¨nh SVM ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n nh√£n c·∫£m x√∫c (happy, sad, neutral).
5. **Hi·ªÉn Th·ªã K·∫øt Qu·∫£**
   - V·∫Ω h√¨nh xung quanh khu√¥n m·∫∑t v√† hi·ªÉn th·ªã nh√£n c·∫£m x√∫c t∆∞∆°ng ·ª©ng.

""")

# ƒê∆∞·ªùng d·∫´n t·ªõi t·ªáp s∆° ƒë·ªì
flow_image_path = os.path.join(Data_DIR, "pipeline.png")

# Ki·ªÉm tra n·∫øu t·ªáp s∆° ƒë·ªì t·ªìn t·∫°i
if os.path.exists(flow_image_path):
    st.markdown("### **S∆° ƒê·ªì Minh H·ªça Lu·ªìng X·ª≠ L√Ω**")
    diagram = Image.open(flow_image_path)  # M·ªü h√¨nh ·∫£nh s∆° ƒë·ªì
    st.image(diagram, caption="Lu·ªìng X·ª≠ L√Ω Nh·∫≠n Di·ªán C·∫£m X√∫c", use_column_width=True)
else:
    st.error("Kh√¥ng t√¨m th·∫•y t·ªáp s∆° ƒë·ªì lu·ªìng x·ª≠ l√Ω. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n t·ªáp!")

#  ·ª®ng D·ª•ng
st.title("·ª®ng D·ª•ng Nh·∫≠n Di·ªán C·∫£m X√∫c")
st.markdown("""
### T·∫£i ·∫¢nh ho·∫∑c S·ª≠ D·ª•ng Webcam ƒë·ªÉ Nh·∫≠n Di·ªán C·∫£m X√∫c
""")


# H√†m d·ª± ƒëo√°n c·∫£m x√∫c
def predict_emotion(face, model, emotions):
    face_resized = cv2.resize(face, (48, 48))  # Resize ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n
    face_flatten = face_resized.flatten().reshape(1, -1)  # Chuy·ªÉn th√†nh vector 1D
    prediction = model.predict(face_flatten)
    return emotions[prediction[0]]

# T·∫£i ·∫£nh t·ª´ ng∆∞·ªùi d√πng
uploaded_file = st.file_uploader("T·∫£i ·∫£nh l√™n ƒë·ªÉ nh·∫≠n di·ªán c·∫£m x√∫c", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    # ƒê·ªçc v√† hi·ªÉn th·ªã ·∫£nh g·ªëc
    image = Image.open(uploaded_file)
    image_np = np.array(image)  # Chuy·ªÉn ·∫£nh sang ƒë·ªãnh d·∫°ng NumPy

    # Sao ch√©p ·∫£nh ƒë·ªÉ x·ª≠ l√Ω
    processed_image = image_np.copy()

    # Ki·ªÉm tra n·∫øu ·∫£nh c√≥ ƒë·ªß 3 k√™nh m√†u
    if len(processed_image.shape) == 3 and processed_image.shape[2] == 3:
        gray_image = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
    else:
        # N·∫øu ·∫£nh ƒë√£ l√† grayscale
        gray_image = processed_image

    # Ph√°t hi·ªán khu√¥n m·∫∑t
    face_cascade = cv2.CascadeClassifier(cascade)
    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.3, minNeighbors=5)

    # L∆∞u tr·ªØ c·∫£m x√∫c ƒë·ªÉ hi·ªÉn th·ªã
    emotions_detected = []

    for (x, y, w, h) in faces:
        # T√≠nh t·ªça ƒë·ªô t√¢m v√† b√°n k√≠nh h√¨nh tr√≤n
        center_x, center_y = x + w // 2, y + h // 2
        radius = max(w, h) // 2

        # V·∫Ω h√¨nh tr√≤n l√™n ·∫£nh ƒë√£ x·ª≠ l√Ω
        cv2.circle(processed_image, (center_x, center_y), radius, (255, 0, 0), 2)

        # D·ª± ƒëo√°n c·∫£m x√∫c
        face = gray_image[y:y+h, x:x+w]
        emotion = predict_emotion(face, model, emotions)
        emotions_detected.append(emotion)

        # Ghi nh√£n c·∫£m x√∫c l√™n ·∫£nh
        cv2.putText(processed_image, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)

    # Hi·ªÉn th·ªã ·∫£nh g·ªëc v√† ·∫£nh x·ª≠ l√Ω c·∫°nh nhau
    col1, col2 = st.columns(2)
    with col1:
        st.image(image, caption="·∫¢nh G·ªëc", use_column_width=True)
    with col2:
        st.image(processed_image, caption="·∫¢nh Sau X·ª≠ L√Ω", use_column_width=True)

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ nh·∫≠n di·ªán c·∫£m x√∫c
    if emotions_detected:
        st.write("### K·∫øt Qu·∫£ Nh·∫≠n Di·ªán C·∫£m X√∫c:")
        for i, emotion in enumerate(emotions_detected, start=1):
            st.write(f"- Khu√¥n m·∫∑t {i}: **{emotion}**")
    else:
        st.write("Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t n√†o!")

# Th√™m ph·∫ßn webcam
st.write("## Nh·∫≠n Di·ªán C·∫£m X√∫c T·ª´ Webcam")
if st.button("B·∫≠t Webcam"):
    st.info("Nh·∫•n 'q' tr√™n c·ª≠a s·ªï webcam ƒë·ªÉ tho√°t.")
    cap = cv2.VideoCapture(0)
    face_cascade = cv2.CascadeClassifier(cascade)

    while True:
        ret, frame = cap.read()
        if not ret:
            st.warning("Kh√¥ng th·ªÉ m·ªü webcam. Vui l√≤ng ki·ªÉm tra l·∫°i!")
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

        for (x, y, w, h) in faces:
            face = gray[y:y+h, x:x+w]
            if face.size > 0:
                emotion = predict_emotion(face, model, emotions)
                # V·∫Ω h√¨nh tr√≤n v√† ghi nh√£n c·∫£m x√∫c
                center_x, center_y = x + w // 2, y + h // 2
                radius = max(w, h) // 2
                cv2.circle(frame, (center_x, center_y), radius, (255, 0, 0), 2)
                cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)

        cv2.imshow("Webcam - Nh·∫≠n Di·ªán C·∫£m X√∫c", frame)

        # Nh·∫•n 'q' ƒë·ªÉ tho√°t
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
